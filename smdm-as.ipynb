{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered 429 Error (Rate Limit Exceeded)\n",
      "Retrying in 15 minutes...ZzZ...\n",
      "...ZzZ...Awake now and trying again.\n",
      "Encountered 429 Error (Rate Limit Exceeded)\n",
      "Retrying in 15 minutes...ZzZ...\n"
     ]
    }
   ],
   "source": [
    "import twitter\n",
    "import sys\n",
    "import time\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "import json\n",
    "from pprint import pprint\n",
    "import operator\n",
    "import networkx \n",
    "import matplotlib.pyplot as plt\t\n",
    "\n",
    "from functools import partial\n",
    "from sys import maxsize as maxint\n",
    "\n",
    "\n",
    "def oauth_login():\n",
    "    CONSUMER_KEY = 'grP4e9xsnpQTlFFK39Bqd6CHQ'\n",
    "    CONSUMER_SECRET = 'I5cqHTmfSAWtu6CrLszGfBToYluzuCPDzW5OkRIWf8DYM6kzMV'\n",
    "    OAUTH_TOKEN = '1232024497575940096-NxtZgyfWlG4PJ5NgFJm5WinJBqyD7S'\n",
    "    OAUTH_TOKEN_SECRET = 'gkvKwO7z8pkXc97BaTPojuDUWuYagx54HiraSNUcsnpUf'\n",
    "    auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    twitter_api = twitter.Twitter(auth=auth)\n",
    "    return twitter_api\n",
    "\n",
    "twitter_api = oauth_login()\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw): \n",
    "    \n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "    \n",
    "        if wait_period > 3600: # Seconds\n",
    "            print('Too many retries. Quitting.', file=sys.stderr)\n",
    "            raise e\n",
    "    \n",
    "        # See https://developer.twitter.com/en/docs/basics/response-codes\n",
    "        # for common codes\n",
    "    \n",
    "        if e.e.code == 401:\n",
    "            print('Encountered 401 Error (Not Authorized)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 429: \n",
    "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
    "            if sleep_when_rate_limited:\n",
    "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5)\n",
    "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print('Encountered {0} Error. Retrying in {1} seconds'.format(e.e.code, wait_period), file=sys.stderr)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "    \n",
    "    wait_period = 2 \n",
    "    error_count = 0 \n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except twitter.api.TwitterHTTPError as e:\n",
    "            error_count = 0 \n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            print(\"BadStatusLine encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                              friends_limit=maxint, followers_limit=maxint):\n",
    "    \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None),\"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # See http://bit.ly/2GcjKJP and http://bit.ly/2rFz90N for details\n",
    "    # on API parameters\n",
    "    \n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids, \n",
    "                              count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids, \n",
    "                                count=5000)\n",
    "\n",
    "    friends_ids, followers_ids = [], []\n",
    "    \n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "                    [get_friends_ids, friends_limit, friends_ids, \"friends\"], \n",
    "                    [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "                ]:\n",
    "        \n",
    "        if limit == 0: continue\n",
    "        \n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "        \n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name: \n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "        \n",
    "            print('Fetched {0} total {1} ids for {2}'.format(len(ids),label, (user_id or screen_name)),file=sys.stderr)\n",
    "        \n",
    "            # XXX: You may want to store data during each iteration to provide an \n",
    "            # an additional layer of protection from exceptional circumstances\n",
    "        \n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "\n",
    "    # Do something useful with the IDs, like store them to disk...\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]\n",
    "\n",
    "#Fetching followers and friends of user 'edmundyu1001'\n",
    "friends_ids, followers_ids = get_friends_followers_ids(twitter_api, \n",
    "                                                       screen_name=\"edmundyu1001\", \n",
    "                                                       friends_limit=5000, \n",
    "                                                       followers_limit=5000)\n",
    "\n",
    "#getting the reciprocal by using the set operation intersection and storing it in reciprocal list\n",
    "reciprocal=list(set(friends_ids)&set(followers_ids))\n",
    "\n",
    "def get_user_profile(twitter_api, screen_names=None, user_ids=None):\n",
    "   \n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_names != None) != (user_ids != None),\"Must have screen_names or user_ids, but not both\"\n",
    "    \n",
    "    items_to_info = {}\n",
    "\n",
    "    items = screen_names or user_ids\n",
    "    \n",
    "    while len(items) > 0:\n",
    "\n",
    "        # Process 100 items at a time per the API specifications for /users/lookup.\n",
    "        # See http://bit.ly/2Gcjfzr for details.\n",
    "        \n",
    "        items_str = ','.join([str(item) for item in items[:100]])\n",
    "        items = items[100:]\n",
    "\n",
    "        if screen_names:\n",
    "            response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                            screen_name=items_str)\n",
    "        else: # user_ids\n",
    "            response = make_twitter_request(twitter_api.users.lookup, \n",
    "                                            user_id=items_str)\n",
    "    \n",
    "        for user_info in response:\n",
    "            if screen_names:\n",
    "                items_to_info[user_info['screen_name']] = user_info\n",
    "            else: # user_ids\n",
    "                items_to_info[user_info['id']] = user_info\n",
    "\n",
    "    return items_to_info\n",
    "\n",
    "#Displaying the user profile of reciprocal friends    \n",
    "pprint(get_user_profile(twitter_api, user_ids=reciprocal[0:5]))\n",
    "\n",
    "#Following function takes screen name and fetches the distance-1, distance-2 friends\n",
    "def crawl_followers_screen_name(twitter_api, screen_name, limit=100, depth=50):\n",
    "\n",
    "    #getting followers and friends by passing screen name\n",
    "    friends_ids, followers_ids = get_friends_followers_ids(twitter_api, screen_name, friends_limit=5000, followers_limit=5000)\n",
    "    #finding reciprocal of friends and followers\n",
    "    reciprocal = set(friends_ids) & set(followers_ids)\n",
    "    #fetching profile of reciprocal list\n",
    "    response = get_user_profile(twitter_api, screen_names=None, user_ids=list(reciprocal)) #make_twitter_request(twitter_api.users.lookup, user_id=reciprocal)\n",
    "    count_dict = {}\n",
    "    for user, val in response.items():\n",
    "        count_dict[user] = val['followers_count']\n",
    "\n",
    "    #fetching top 5 followers by sorting the list\n",
    "    count_dict = dict(reversed(sorted(count_dict.items(), key=operator.itemgetter(1))))\n",
    "    return (count_dict)\n",
    "\n",
    "#Following function takes id and fetches the distance-1, distance-2 friends \n",
    "def crawl_followers_id(twitter_api, id, limit=100, depth=50):\n",
    "\n",
    "     #getting followers and friends by passing id\n",
    "    friends_ids, followers_ids = get_friends_followers_ids(twitter_api, user_id=id, friends_limit=5000, followers_limit=5000)\n",
    "    #finding reciprocal\n",
    "    reciprocal = set(friends_ids) & set(followers_ids)\n",
    "    #fetching profiles of reciprocal list\n",
    "    response = get_user_profile(twitter_api, screen_names=None, user_ids=list(reciprocal)) \n",
    "    count_dict = {}\n",
    "    for user, val in response.items():\n",
    "        count_dict[user] = val['followers_count']\n",
    "\n",
    "    #fectching top 5 people by sorting\n",
    "    count_dict = dict(reversed(sorted(count_dict.items(), key=operator.itemgetter(1))))\n",
    "    return (count_dict)\n",
    "\n",
    "screen_name = \"edmundyu1001\"\n",
    "\n",
    "\n",
    "result = {}\n",
    "\n",
    "#storing crawl_followers_screen_name result in result dictionary\n",
    "result.update(crawl_followers_screen_name(twitter_api, screen_name, limit=100, depth=50))\n",
    "\n",
    "#getting top 5 people\n",
    "while len(result) > 5:\n",
    "    result.popitem()\n",
    "    \n",
    "#Plotting the graph \n",
    "G = networkx.Graph()\n",
    "#plot the first node or primary node\n",
    "G.add_node(screen_name)\n",
    "for i in list(result):\n",
    "    #adding other nodes and edges\n",
    "    G.add_node(i)\n",
    "    G.add_edge(screen_name, i)\n",
    "\n",
    "#Getting the user_ids from the dictionary\n",
    "ids = result.keys()\n",
    "ids_list = list(ids)\n",
    "\n",
    "\n",
    "#These lists will store the result of crawling\n",
    "crawlResult1 = {}\n",
    "crawlResult2 = {}\n",
    "\n",
    "\n",
    "#Printing the output dictionary \n",
    "print(result)\n",
    "\n",
    "#Fetching next 100 nodes\n",
    "for x in range(30):\n",
    "    i = ids_list[x]\n",
    "    crawlResult1 = crawl_followers_id(twitter_api, i, depth=50, limit=100)\n",
    "    crawlResult2 = crawlResult1\n",
    "    \n",
    "    while len(crawlResult2) > 5:\n",
    "        crawlResult2.popitem()\n",
    "\n",
    "    #Plotting the graph for other nodes\n",
    "    for k in list(crawlResult2):\n",
    "        G.add_node(k)\n",
    "        G.add_edge(i, k)\n",
    "\n",
    "    #getting more nodes\n",
    "    for k in (list(crawlResult2.keys())):\n",
    "        ids_list.append(k)\n",
    "        \n",
    "#prints the users and total number of the next nodes\n",
    "print(ids_list)\n",
    "print(len(ids_list))\n",
    "    \n",
    "#Displaying the graph\n",
    "networkx.draw(G, with_labels = True)\n",
    "plt.draw()\n",
    "plt.show()\n",
    "\n",
    "#Writing final output to a file\n",
    "f = open(\"output.txt\",\"w\")\n",
    "f.write(\"Create social network\\n\")\n",
    "f.write(\"\\nAverage Distance is: \"+str(networkx.average_shortest_path_length(G)))\n",
    "f.write(\"\\nAverage Diameter is: \"+str(networkx.diameter(G)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
# Twitter_Data_Analysis
